{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22129987-1d0e-415e-96a5-3beae57f249f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T22:09:36.629365Z",
     "iopub.status.busy": "2024-01-08T22:09:36.628736Z",
     "iopub.status.idle": "2024-01-08T22:09:36.637043Z",
     "shell.execute_reply": "2024-01-08T22:09:36.635305Z",
     "shell.execute_reply.started": "2024-01-08T22:09:36.629338Z"
    }
   },
   "source": [
    "# Solution Test Custom Functions Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3fb94f6-53e1-4433-8d29-489d69d3c516",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T22:09:55.042193Z",
     "iopub.status.busy": "2024-01-08T22:09:55.041794Z",
     "iopub.status.idle": "2024-01-08T22:09:55.066822Z",
     "shell.execute_reply": "2024-01-08T22:09:55.066160Z",
     "shell.execute_reply.started": "2024-01-08T22:09:55.042167Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/codingdojo/Documents/GitHub/_CURRICULUM/_ACTIVITIES/adv-ml-wk02-deep-nlp-codealongs/Lecture 1 Pt1 - Making a Custom Module',\n",
       " '/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python310.zip',\n",
       " '/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10',\n",
       " '/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "716e76e6-bb63-4cdc-a4ee-338f431f2b95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T22:10:37.210544Z",
     "iopub.status.busy": "2024-01-08T22:10:37.210105Z",
     "iopub.status.idle": "2024-01-08T22:10:37.221937Z",
     "shell.execute_reply": "2024-01-08T22:10:37.220374Z",
     "shell.execute_reply.started": "2024-01-08T22:10:37.210484Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/codingdojo/Documents/GitHub/_CURRICULUM/_ACTIVITIES/adv-ml-wk02-deep-nlp-codealongs'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# os.path.abspath('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8cf7afb0-29c1-4ea8-bd0d-bf85cb1b97a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T22:10:42.327297Z",
     "iopub.status.busy": "2024-01-08T22:10:42.326894Z",
     "iopub.status.idle": "2024-01-08T22:10:42.334265Z",
     "shell.execute_reply": "2024-01-08T22:10:42.333231Z",
     "shell.execute_reply.started": "2024-01-08T22:10:42.327272Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(os.path.abspath('../'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3a8785c-89c3-4750-a6f3-ccbc44ba9c18",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T22:10:46.012865Z",
     "iopub.status.busy": "2024-01-08T22:10:46.012475Z",
     "iopub.status.idle": "2024-01-08T22:10:46.035022Z",
     "shell.execute_reply": "2024-01-08T22:10:46.020736Z",
     "shell.execute_reply.started": "2024-01-08T22:10:46.012840Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/codingdojo/Documents/GitHub/_CURRICULUM/_ACTIVITIES/adv-ml-wk02-deep-nlp-codealongs/Lecture 1 Pt1 - Making a Custom Module',\n",
       " '/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python310.zip',\n",
       " '/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10',\n",
       " '/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/lib-dynload',\n",
       " '',\n",
       " '/opt/homebrew/Caskroom/miniforge/base/envs/dojo-env/lib/python3.10/site-packages',\n",
       " '/Users/codingdojo/Documents/GitHub/_CURRICULUM/_ACTIVITIES/adv-ml-wk02-deep-nlp-codealongs']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a903056b-a4a9-4da5-88c0-5fd3a1285486",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T22:11:16.099408Z",
     "iopub.status.busy": "2024-01-08T22:11:16.099009Z",
     "iopub.status.idle": "2024-01-08T22:11:16.135411Z",
     "shell.execute_reply": "2024-01-08T22:11:16.135016Z",
     "shell.execute_reply.started": "2024-01-08T22:11:16.099383Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3de957bd-abf0-4f7b-8829-a5d704557de6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T22:12:42.765236Z",
     "iopub.status.busy": "2024-01-08T22:12:42.764511Z",
     "iopub.status.idle": "2024-01-08T22:12:42.835458Z",
     "shell.execute_reply": "2024-01-08T22:12:42.835070Z",
     "shell.execute_reply.started": "2024-01-08T22:12:42.765201Z"
    }
   },
   "outputs": [],
   "source": [
    "import custom_package_SOLUTION as cp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "828d0297-36c4-4c77-9f19-e7846596d2bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T22:12:56.526328Z",
     "iopub.status.busy": "2024-01-08T22:12:56.525693Z",
     "iopub.status.idle": "2024-01-08T22:12:56.585117Z",
     "shell.execute_reply": "2024-01-08T22:12:56.584702Z",
     "shell.execute_reply.started": "2024-01-08T22:12:56.526300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module custom_package_SOLUTION.evaluation in custom_package_SOLUTION:\n",
      "\n",
      "NAME\n",
      "    custom_package_SOLUTION.evaluation\n",
      "\n",
      "FUNCTIONS\n",
      "    classification_metrics(y_true, y_pred, label='', output_dict=False, figsize=(8, 4), normalize='true', cmap='Blues', colorbar=False, values_format='.2f')\n",
      "        Modified version of classification metrics function from Intro to Machine Learning.\n",
      "        Updates:\n",
      "        - Reversed raw counts confusion matrix cmap  (so darker==more).\n",
      "        - Added arg for normalized confusion matrix values_format\n",
      "    \n",
      "    convert_y_to_sklearn_classes(y, verbose=False)\n",
      "    \n",
      "    evaluate_classification(model, X_train, y_train, X_test, y_test, figsize=(6, 4), normalize='true', output_dict=False, cmap_train='Blues', cmap_test='Reds', colorbar=False)\n",
      "    \n",
      "    evaluate_classification_network(model, X_train=None, y_train=None, X_test=None, y_test=None, history=None, history_figsize=(6, 6), figsize=(6, 4), normalize='true', output_dict=False, cmap_train='Blues', cmap_test='Reds', values_format='.2f', colorbar=False)\n",
      "        Evaluates a neural network classification task using either\n",
      "        separate X and y arrays or a tensorflow Dataset\n",
      "        \n",
      "        Data Args:\n",
      "            X_train (array, or Dataset)\n",
      "            y_train (array, or None if using a Dataset\n",
      "            X_test (array, or Dataset)\n",
      "            y_test (array, or None if using a Dataset)\n",
      "            history (history object)\n",
      "    \n",
      "    get_true_pred_labels(model, ds)\n",
      "        Gets the labels and predicted probabilities from a Tensorflow model and Dataset object.\n",
      "        Adapted from source: https://stackoverflow.com/questions/66386561/keras-classification-report-accuracy-is-different-between-model-predict-accurac\n",
      "    \n",
      "    plot_history(history, figsize=(6, 8))\n",
      "\n",
      "FILE\n",
      "    /Users/codingdojo/Documents/GitHub/_CURRICULUM/_ACTIVITIES/adv-ml-wk02-deep-nlp-codealongs/custom_package_SOLUTION/evaluation.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cp.evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "881e5645-1274-4c40-8ec8-a786ecd08622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-08T22:13:10.095883Z",
     "iopub.status.busy": "2024-01-08T22:13:10.095224Z",
     "iopub.status.idle": "2024-01-08T22:13:10.163166Z",
     "shell.execute_reply": "2024-01-08T22:13:10.162610Z",
     "shell.execute_reply.started": "2024-01-08T22:13:10.095855Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module custom_package_SOLUTION.nlp in custom_package_SOLUTION:\n",
      "\n",
      "NAME\n",
      "    custom_package_SOLUTION.nlp\n",
      "\n",
      "FUNCTIONS\n",
      "    batch_preprocess_texts(texts, nlp=None, remove_stopwords=True, remove_punct=True, use_lemmas=False, disable=['ner'], batch_size=50, n_process=-1)\n",
      "        Efficiently preprocess a collection of texts using nlp.pipe()\n",
      "        Args:\n",
      "            texts (collection of strings): collection of texts to process (e.g. df['text'])\n",
      "            nlp (spacy pipe), optional): Spacy nlp pipe. Defaults to None; if None, it creates a default 'en_core_web_sm' pipe.\n",
      "            remove_stopwords (bool, optional): Controls stopword removal. Defaults to True.\n",
      "            remove_punct (bool, optional): Controls punctuation removal. Defaults to True.\n",
      "            use_lemmas (bool, optional): lemmatize tokens. Defaults to False.\n",
      "            disable (list of strings, optional): named pipeline elements to disable. Defaults to [\"ner\"]: Used with nlp.pipe(disable=disable)\n",
      "            batch_size (int, optional): Number of texts to process in a batch. Defaults to 50.\n",
      "            n_process (int, optional): Number of CPU processors to use. Defaults to -1 (meaning all CPU cores).\n",
      "        Returns:\n",
      "            list of tokens\n",
      "    \n",
      "    get_ngram_measures_finder(tokens, ngrams=2, measure='raw_freq', top_n=None, min_freq=1, words_colname='Words')\n",
      "    \n",
      "    make_custom_nlp(disable=['ner'], contractions=[\"don't\", \"can't\", \"couldn't\", \"you'd\", \"I'll\"], stopwords_to_add=[], stopwords_to_remove=[], spacy_model='en_core_web_sm')\n",
      "        Returns a custom spacy nlp pipeline.\n",
      "        \n",
      "        Args:\n",
      "                disable (list, optional): Names of pipe components to disable. Defaults to [\"ner\"].\n",
      "                contractions (list, optional): List of contractions to add as special cases. Defaults to [\"don't\", \"can't\", \"couldn't\", \"you'd\", \"I'll\"].\n",
      "                stopwords_to_add(list, optional): List of words to set as stopwords (word.is_stop=True)\n",
      "                stopwords_to_remove(list, optional): List of words to remove from stopwords (word.is_stop=False)\n",
      "                        \n",
      "        Returns:\n",
      "                nlp pipeline: spacy pipeline with special cases and updated nlp..Default.stopwords\n",
      "    \n",
      "    make_text_vectorization_layer(train_ds, max_tokens=None, split='whitespace', standardize='lower_and_strip_punctuation', output_mode='int', output_sequence_length=None, ngrams=None, pad_to_max_tokens=False, verbose=True, **kwargs)\n",
      "    \n",
      "    preprocess_text(txt, nlp=None, remove_stopwords=True, remove_punct=True, use_lemmas=False)\n",
      "        Preprocess text into tokens/lemmas. \n",
      "        \n",
      "        Args:\n",
      "                txt (string): text to process\n",
      "                nlp (spacy pipe), optional): Spacy nlp pipe. Defaults to None\n",
      "                                                                        if None, it creates a default 'en_core_web_sm' pipe.\n",
      "                remove_stopwords (bool, optional): Controls stopword removal. Defaults to True.\n",
      "                remove_punct (bool, optional): Controls punctuation removal. Defaults to True.\n",
      "                use_lemmas (bool, optional): lemmatize tokens. Defaults to False.\n",
      "        \n",
      "        Returns:\n",
      "                list: list of tokens/lemmas\n",
      "\n",
      "FILE\n",
      "    /Users/codingdojo/Documents/GitHub/_CURRICULUM/_ACTIVITIES/adv-ml-wk02-deep-nlp-codealongs/custom_package_SOLUTION/nlp.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(cp.nlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f17ca07-8ea8-40ad-b27a-38a95c58e98e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
